{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "# from sklearn.pipeline import Pipeline\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.tree import DecisionTreeClassifier\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.svm import SVC\n",
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "# from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, classification_report, confusion_matrix\n",
    "# from imblearn.over_sampling import SMOTE\n",
    "# from imblearn.under_sampling import TomekLinks\n",
    "# from imblearn.pipeline import Pipeline\n",
    "\n",
    "# from imblearn.over_sampling import RandomOverSampler\n",
    "# from imblearn.combine import SMOTEENN\n",
    "# from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "# from sklearn.pipeline import Pipeline\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.tree import DecisionTreeClassifier\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.svm import SVC\n",
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "# # Cargar los datos\n",
    "# test = pd.read_csv(r'C:\\Users\\de969\\OneDrive\\Escritorio\\proyecto, machine learnig\\_marketing\\data\\test.csv',sep='\\t')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# median_income = test['Income'].median()\n",
    "# test['Income'].fillna(median_income, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# from pathlib import Path\n",
    "\n",
    "# def read_pickle(file_path: str):\n",
    "#     \"\"\"\n",
    "#     Read data from a Pickle file.\n",
    "\n",
    "#     Args:\n",
    "#         file_path (str): Path of the Pickle file.\n",
    "\n",
    "#     Returns:\n",
    "#         object: Data loaded from the Pickle file, or None if there is an error.\n",
    "#     \"\"\"\n",
    "#     try:\n",
    "#         with open(file_path, \"rb\") as f:\n",
    "#             data = pickle.load(f)\n",
    "#         print(\"Pickle file read: OK\")\n",
    "#         return data\n",
    "#     except (FileNotFoundError, IOError, pickle.PickleError) as err:\n",
    "#         print(f\"Failed to read Pickle file {file_path}: {err}\")\n",
    "#         return None\n",
    "\n",
    "# # Leer el modelo desde el archivo Pickle\n",
    "\n",
    "# import joblib\n",
    "\n",
    "# # Cargar el modelo desde el archivo .pkl\n",
    "# # loaded_model = joblib.load('_marketing\\models\\mejor_modelo.pkl')\n",
    "\n",
    "\n",
    "# modelo = read_pickle(\"_marketing\\models\\mejor_modelo.pkl\")\n",
    "\n",
    "# from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "# import pandas as pd\n",
    "\n",
    "# test = pd.read_csv(r'C:\\Users\\de969\\OneDrive\\Escritorio\\proyecto, machine learnig\\_marketing\\data\\test.csv',sep='\\t')\n",
    "# median_income = test['Income'].median()\n",
    "# test['Income'].fillna(median_income, inplace=True)\n",
    "\n",
    "# features = ['Year_Birth', 'Income', 'Kidhome', 'Teenhome', 'Recency', 'MntWines',\n",
    "#             'MntFruits', 'MntMeatProducts', 'MntFishProducts', 'MntSweetProducts',\n",
    "#             'MntGoldProds', 'NumDealsPurchases', 'NumWebPurchases',\n",
    "#             'NumCatalogPurchases', 'NumStorePurchases', 'NumWebVisitsMonth',\n",
    "#             'Z_CostContact', 'Z_Revenue'] \n",
    "# target = 'Response' \n",
    "\n",
    "# X = test[features]\n",
    "# y = test[target]\n",
    "# # predicciones\n",
    "# predictions = modelo.predict(X)\n",
    "\n",
    "\n",
    "\n",
    "# from sklearn.metrics import roc_auc_score\n",
    "# accuracy = accuracy_score(y, predictions)\n",
    "# precision = precision_score(y, predictions)\n",
    "# recall = recall_score(y, predictions)\n",
    "# f1 = f1_score(y, predictions)\n",
    "# roc_auc = roc_auc_score(y, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os \n",
    "# os.getcwd()\n",
    "# os.chdir(os.path.dirname(os.getcwd()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# # Seleccionar las características y el objetivo\n",
    "# features = ['Year_Birth', 'Income', 'Kidhome', 'Teenhome', 'Recency', 'MntWines',\n",
    "#             'MntFruits', 'MntMeatProducts', 'MntFishProducts', 'MntSweetProducts',\n",
    "#             'MntGoldProds', 'NumDealsPurchases', 'NumWebPurchases',\n",
    "#             'NumCatalogPurchases', 'NumStorePurchases', 'NumWebVisitsMonth',\n",
    "#             'Z_CostContact', 'Z_Revenue']  # Variables predictoras\n",
    "# target = 'Response'  # Variable objetivo\n",
    "\n",
    "# X_test = test[features]\n",
    "# y_test = test[target]\n",
    "\n",
    "# # # Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "# # X_test[features], y_train, y_test = train_test_split(test[features], test[target], test_size=0.2, random_state=42)\n",
    "\n",
    "# # # Aplicar resampling al conjunto de entrenamiento\n",
    "# # resampler = SMOTEENN(random_state=42)\n",
    "# # X_train_resampled, y_train_resampled = resampler.fit_resample(X_train, y_train)\n",
    "\n",
    "\n",
    "# # import os\n",
    "\n",
    "# # modelo_file = \"_marketing\\models\\mejor_modelo.pkl\"\n",
    "# # if not os.path.exists(modelo_file):\n",
    "# #     print(\"El archivo modelo no existe en la ubicación especificada.\")\n",
    "\n",
    "# import pickle\n",
    "# from pathlib import Path\n",
    "\n",
    "# def read_pickle(file_path: str):\n",
    "#     \"\"\"\n",
    "#     Read data from a Pickle file.\n",
    "\n",
    "#     Args:\n",
    "#         file_path (str): Path of the Pickle file.\n",
    "\n",
    "#     Returns:\n",
    "#         object: Data loaded from the Pickle file, or None if there is an error.\n",
    "#     \"\"\"\n",
    "#     try:\n",
    "#         with open(file_path, \"rb\") as f:\n",
    "#             data = pickle.load(f)\n",
    "#         print(\"Pickle file read: OK\")\n",
    "#         return data\n",
    "#     except (FileNotFoundError, IOError, pickle.PickleError) as err:\n",
    "#         print(f\"Failed to read Pickle file {file_path}: {err}\")\n",
    "#         return None\n",
    "\n",
    "# # Leer el modelo desde el archivo Pickle\n",
    "\n",
    "# import joblib\n",
    "\n",
    "# # Cargar el modelo desde el archivo .pkl\n",
    "# # loaded_model = joblib.load('_marketing\\models\\mejor_modelo.pkl')\n",
    "\n",
    "\n",
    "# modelo = read_pickle(\"_marketing\\models\\mejor_modelo.pkl\")\n",
    "\n",
    "# # Evaluar el mejor modelo en el conjunto de prueba\n",
    "# y_pred = modelo.predict(X_test)\n",
    "# accuracy = accuracy_score(y_test, y_pred)\n",
    "# precision = precision_score(y_test, y_pred)\n",
    "# recall = recall_score(y_test, y_pred)\n",
    "# f1 = f1_score(y_test, y_pred)\n",
    "# roc_auc = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "# # Imprimir las métricas de evaluación\n",
    "# print(\"Métricas de evaluación en el conjunto de prueba:\")\n",
    "# print(\"Accuracy:\", accuracy)\n",
    "# print(\"Precision:\", precision)\n",
    "# print(\"Recall:\", recall)\n",
    "# print(\"F1-score:\", f1)\n",
    "# print(\"ROC AUC:\", roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# # Crear el pipeline con escalado de características, técnica de resampling y modelo de clasificación\n",
    "# pipeline_smote_tomek = Pipeline([\n",
    "#     ('scaler', StandardScaler()),\n",
    "#     ('resampler', SMOTE(sampling_strategy='auto')),\n",
    "#     ('undersampler', TomekLinks(sampling_strategy='majority')),\n",
    "#     ('classifier', RandomForestClassifier())\n",
    "# ])\n",
    "\n",
    "# # Definir los parámetros del grid search\n",
    "# param_grid_smote_tomek = {\n",
    "#     'classifier__n_estimators': [50, 100, 200]\n",
    "# }\n",
    "\n",
    "# # Realizar la búsqueda de hiperparámetros utilizando GridSearchCV\n",
    "# grid_search_smote_tomek = GridSearchCV(pipeline_smote_tomek, param_grid_smote_tomek, cv=5, scoring='accuracy')\n",
    "# grid_search_smote_tomek.fit(X_train, y_train)\n",
    "\n",
    "# # Obtener los resultados de la búsqueda de hiperparámetros\n",
    "# best_model_smote_tomek = grid_search_smote_tomek.best_estimator_\n",
    "# best_params_smote_tomek = grid_search_smote_tomek.best_params_\n",
    "# best_score_smote_tomek = grid_search_smote_tomek.best_score_\n",
    "\n",
    "# # Imprimir los resultados\n",
    "# print(\"Resultados de la búsqueda de hiperparámetros para SMOTE + TomekLinks:\")\n",
    "# print(\"Mejor modelo:\", best_model_smote_tomek)\n",
    "# print(\"Mejores parámetros:\", best_params_smote_tomek)\n",
    "# print(\"Mejor puntuación:\", best_score_smote_tomek)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El archivo modelo no existe en la ubicación especificada.\n"
     ]
    }
   ],
   "source": [
    "# import os\n",
    "\n",
    "# modelo_file = \"_marketing\\models\\mejor_modelo.pkl\"\n",
    "# if not os.path.exists(modelo_file):\n",
    "#     print(\"El archivo modelo no existe en la ubicación especificada.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to read Pickle file _marketing/models/mejor_modelo.pkl: [Errno 2] No such file or directory: '_marketing/models/mejor_modelo.pkl'\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# modelo = read_pickle(\"_marketing/models/mejor_modelo.pkl\")\n",
    "# print(modelo)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
