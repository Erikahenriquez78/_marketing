{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f = open(hamListPath, 'rb')\n",
    "#  hamList = pickle.load(f)\n",
    "#  f.close()\n",
    "# f = open(hamListPath, 'wb')\n",
    "# pickle.dump(hamList, f)\n",
    "# f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, classification_report, confusion_matrix\n",
    "\n",
    "# Cargar los datos\n",
    "data = pd.read_csv(r'../data/train.csv',sep=',')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1792 entries, 0 to 1791\n",
      "Data columns (total 31 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   index                  1792 non-null   int64  \n",
      " 1   ID                     1792 non-null   int64  \n",
      " 2   Year_Birth             1792 non-null   int64  \n",
      " 3   Education              1792 non-null   object \n",
      " 4   Marital_Status         1792 non-null   object \n",
      " 5   Income                 1792 non-null   float64\n",
      " 6   Dt_Customer            1792 non-null   object \n",
      " 7   Recency                1792 non-null   int64  \n",
      " 8   MntWines               1792 non-null   int64  \n",
      " 9   MntFruits              1792 non-null   int64  \n",
      " 10  MntMeatProducts        1792 non-null   int64  \n",
      " 11  MntFishProducts        1792 non-null   int64  \n",
      " 12  MntSweetProducts       1792 non-null   int64  \n",
      " 13  MntGoldProds           1792 non-null   int64  \n",
      " 14  NumDealsPurchases      1792 non-null   int64  \n",
      " 15  NumWebPurchases        1792 non-null   int64  \n",
      " 16  NumCatalogPurchases    1792 non-null   int64  \n",
      " 17  NumStorePurchases      1792 non-null   int64  \n",
      " 18  NumWebVisitsMonth      1792 non-null   int64  \n",
      " 19  AcceptedCmp3           1792 non-null   int64  \n",
      " 20  AcceptedCmp4           1792 non-null   int64  \n",
      " 21  AcceptedCmp5           1792 non-null   int64  \n",
      " 22  AcceptedCmp1           1792 non-null   int64  \n",
      " 23  AcceptedCmp2           1792 non-null   int64  \n",
      " 24  Complain               1792 non-null   int64  \n",
      " 25  Z_Revenue              1792 non-null   int64  \n",
      " 26  Response               1792 non-null   int64  \n",
      " 27  Marital_Status_Binary  1792 non-null   int64  \n",
      " 28  Kids                   1792 non-null   int64  \n",
      " 29  date                   1792 non-null   object \n",
      " 30  monto_gastado          1792 non-null   int64  \n",
      "dtypes: float64(1), int64(26), object(4)\n",
      "memory usage: 434.1+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "median_income = data['Income'].median()\n",
    "data['Income'].fillna(median_income, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1792 entries, 0 to 1791\n",
      "Data columns (total 31 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   index                  1792 non-null   int64  \n",
      " 1   ID                     1792 non-null   int64  \n",
      " 2   Year_Birth             1792 non-null   int64  \n",
      " 3   Education              1792 non-null   object \n",
      " 4   Marital_Status         1792 non-null   object \n",
      " 5   Income                 1792 non-null   float64\n",
      " 6   Dt_Customer            1792 non-null   object \n",
      " 7   Recency                1792 non-null   int64  \n",
      " 8   MntWines               1792 non-null   int64  \n",
      " 9   MntFruits              1792 non-null   int64  \n",
      " 10  MntMeatProducts        1792 non-null   int64  \n",
      " 11  MntFishProducts        1792 non-null   int64  \n",
      " 12  MntSweetProducts       1792 non-null   int64  \n",
      " 13  MntGoldProds           1792 non-null   int64  \n",
      " 14  NumDealsPurchases      1792 non-null   int64  \n",
      " 15  NumWebPurchases        1792 non-null   int64  \n",
      " 16  NumCatalogPurchases    1792 non-null   int64  \n",
      " 17  NumStorePurchases      1792 non-null   int64  \n",
      " 18  NumWebVisitsMonth      1792 non-null   int64  \n",
      " 19  AcceptedCmp3           1792 non-null   int64  \n",
      " 20  AcceptedCmp4           1792 non-null   int64  \n",
      " 21  AcceptedCmp5           1792 non-null   int64  \n",
      " 22  AcceptedCmp1           1792 non-null   int64  \n",
      " 23  AcceptedCmp2           1792 non-null   int64  \n",
      " 24  Complain               1792 non-null   int64  \n",
      " 25  Z_Revenue              1792 non-null   int64  \n",
      " 26  Response               1792 non-null   int64  \n",
      " 27  Marital_Status_Binary  1792 non-null   int64  \n",
      " 28  Kids                   1792 non-null   int64  \n",
      " 29  date                   1792 non-null   object \n",
      " 30  monto_gastado          1792 non-null   int64  \n",
      "dtypes: float64(1), int64(26), object(4)\n",
      "memory usage: 434.1+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "index  ID     Year_Birth  Education   Marital_Status  Income   Dt_Customer  Recency  MntWines  MntFruits  MntMeatProducts  MntFishProducts  MntSweetProducts  MntGoldProds  NumDealsPurchases  NumWebPurchases  NumCatalogPurchases  NumStorePurchases  NumWebVisitsMonth  AcceptedCmp3  AcceptedCmp4  AcceptedCmp5  AcceptedCmp1  AcceptedCmp2  Complain  Z_Revenue  Response  Marital_Status_Binary  Kids  date      monto_gastado\n",
       "0      5524   66          Graduation  Single          58138.0  04-09-2012   58       635       88         546              172              88                88            3                  8                10                   4                  7                  0             0             0             0             0             0         11         1         0                      0     Sep       1617             1\n",
       "1      2174   69          Graduation  Single          46344.0  08-03-2014   38       11        1          6                2                1                 6             2                  1                1                    2                  5                  0             0             0             0             0             0         11         0         0                      2     March     27               1\n",
       "1504   3584   68          PhD         Single          49667.0  20-08-2012   35       1181      26         120              17               13                39            2                  5                10                   5                  8                  1             0             0             0             0             0         11         1         0                      0     Aug       1396             1\n",
       "1501   5751   50          2n Cycle    Divorced        31163.0  13-02-2014   54       2         3          10               11               2                 10            1                  1                0                    3                  6                  0             0             0             0             0             0         11         0         0                      1     Feb       38               1\n",
       "1500   4093   48          Master      Together        53253.0  11-02-2013   61       216       9          57               20               9                 125           7                  4                3                    5                  5                  0             0             0             0             0             0         11         0         1                      2     Feb       436              1\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                       ..\n",
       "730    5329   74          PhD         Divorced        35946.0  27-09-2013   24       8         0          3                0                0                 0             1                  0                0                    3                  5                  0             0             0             0             0             0         11         0         0                      2     Sep       11               1\n",
       "729    11101  32          Graduation  Together        89891.0  15-04-2013   17       412       22         132              59               28                183           1                  11               6                    8                  4                  0             0             1             0             0             0         11         0         1                      0     Apr       836              1\n",
       "727    437    47          Master      Divorced        75012.0  25-01-2014   41       294       142        218              164              58                151           1                  3                8                    11                 1                  0             0             0             0             0             0         11         0         0                      0     Yan       1027             1\n",
       "726    6086   68          Graduation  Married         80395.0  23-11-2013   62       445       25         706              80               76                48            1                  6                5                    12                 2                  0             0             0             1             0             0         11         0         1                      0     November  1380             1\n",
       "2239   9405   69          PhD         Married         52869.0  15-10-2012   40       84        3          61               2                1                 21            3                  3                1                    4                  7                  0             0             0             0             0             0         11         1         1                      2     Oct       172              1\n",
       "Length: 1792, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados de la búsqueda de hiperparámetros:\n",
      "Mejor modelo: Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('classifier', RandomForestClassifier(n_estimators=50))])\n",
      "Mejores parámetros: {'classifier': RandomForestClassifier(n_estimators=50), 'classifier__n_estimators': 50}\n",
      "Mejor puntuación: 0.9078873763108305\n",
      "Métricas de evaluación en el conjunto de prueba:\n",
      "Accuracy: 0.912828947368421\n",
      "Precision: 0.886435331230284\n",
      "Recall: 0.9429530201342282\n",
      "F1-score: 0.9138211382113822\n",
      "ROC AUC: 0.9134119939380818\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, classification_report, confusion_matrix\n",
    "\n",
    "import os\n",
    "\n",
    "\n",
    "# Obtener la ruta del directorio actual\n",
    "# directorio_actual = os.getcwd()\n",
    "\n",
    "# # Construir la ruta completa al archivo train.csv en la carpeta \"data\"\n",
    "# ruta_train = os.path.join(directorio_actual, \"data\", \"train.csv\")\n",
    "\n",
    "# # Leer el archivo CSV en un DataFrame\n",
    "# data = pd.read_csv(ruta_train)\n",
    "# Cargar los datos\n",
    "data = pd.read_csv('../data/train.csv')\n",
    "\n",
    "# Seleccionar las características y el objetivo\n",
    "features = ['Year_Birth', 'Income', 'Recency', 'MntWines',\n",
    "            'MntFruits', 'MntMeatProducts', 'MntFishProducts', 'MntSweetProducts',\n",
    "            'MntGoldProds', 'NumDealsPurchases', 'NumWebPurchases',\n",
    "            'NumCatalogPurchases', 'NumStorePurchases', 'NumWebVisitsMonth',\n",
    "            'Z_Revenue']  # Variables predictoras\n",
    "target = 'Response'  # Variable objetivo\n",
    "import pandas as pd\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "\n",
    "# Aplicar SMOTE para oversampling\n",
    "oversampler = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = oversampler.fit_resample(data[features], data[target])\n",
    "\n",
    "# Crear un nuevo DataFrame con las características y el objetivo balanceados\n",
    "balanced_data = pd.DataFrame(X_resampled, columns=features)\n",
    "balanced_data[target] = y_resampled\n",
    "\n",
    "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(balanced_data[features], balanced_data[target], test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "# X_train, X_test, y_train, y_test = train_test_split(data[features], data[target], test_size=0.2, random_state=42)\n",
    "\n",
    "# # Aplicar oversampling al conjunto de entrenamiento\n",
    "# oversampler = RandomOverSampler(random_state=42)\n",
    "# X_train_resampled, y_train_resampled = oversampler.fit_resample(X_train, y_train)\n",
    "\n",
    "# Crear el pipeline con escalado de características y modelo de clasificación\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('classifier', None)\n",
    "])\n",
    "\n",
    "# Definir los parámetros del grid search para cada modelo\n",
    "param_grid = [\n",
    "    {\n",
    "        'classifier': [LogisticRegression(solver='liblinear')],\n",
    "        'classifier__C': [0.1, 1, 10]\n",
    "    },\n",
    "    {\n",
    "        'classifier': [DecisionTreeClassifier()],\n",
    "        'classifier__max_depth': [8, 10, 15]\n",
    "    },\n",
    "    {\n",
    "        'classifier': [RandomForestClassifier()],\n",
    "        'classifier__n_estimators': [50, 100, 200]\n",
    "    },\n",
    "    {\n",
    "        'classifier': [SVC()],\n",
    "        'classifier__C': [0.1, 1, 10],\n",
    "        'classifier__kernel': ['linear', 'rbf']\n",
    "    },\n",
    "    {\n",
    "        'classifier': [KNeighborsClassifier()],\n",
    "        'classifier__n_neighbors': [3, 5, 7]\n",
    "    }\n",
    "]\n",
    "\n",
    "# Realizar la búsqueda de hiperparámetros utilizando GridSearchCV\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Obtener los resultados de la búsqueda de hiperparámetros\n",
    "results = grid_search.cv_results_\n",
    "best_model = grid_search.best_estimator_\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "# Imprimir los resultados\n",
    "print(\"Resultados de la búsqueda de hiperparámetros:\")\n",
    "print(\"Mejor modelo:\", best_model)\n",
    "print(\"Mejores parámetros:\", best_params)\n",
    "print(\"Mejor puntuación:\", best_score)\n",
    "\n",
    "# Evaluar el mejor modelo en el conjunto de prueba\n",
    "y_pred = best_model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "# Imprimir las métricas de evaluación\n",
    "print(\"Métricas de evaluación en el conjunto de prueba:\")\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1-score:\", f1)\n",
    "print(\"ROC AUC:\", roc_auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Guardar el mejor modelo en un archivo pickle\n",
    "with open('models\\mejor_modelo1.pkl', 'wb') as file:\n",
    "    pickle.dump(best_model, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de969\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\de969\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\de969\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\de969\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\de969\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\de969\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\de969\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\de969\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\de969\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\de969\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\de969\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\de969\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\de969\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\de969\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\de969\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados de la búsqueda de hiperparámetros:\n",
      "Mejor modelo: Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('model', RandomForestClassifier(n_estimators=50))])\n",
      "Mejores parámetros: {'model': RandomForestClassifier(n_estimators=50), 'model__n_estimators': 50}\n",
      "Mejor puntuación: 0.9616426684842804\n",
      "Métricas de evaluación en el conjunto de prueba:\n",
      "Accuracy: 0.8579387186629527\n",
      "Precision: 0.5\n",
      "Recall: 0.29411764705882354\n",
      "F1-score: 0.37037037037037035\n",
      "ROC AUC: 0.6227081741787625\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Cargar los datos\n",
    "data = pd.read_csv('../data/train.csv')\n",
    "\n",
    "# Seleccionar las características y el objetivo\n",
    "features = ['Year_Birth', 'Income', 'Recency', 'MntWines',\n",
    "            'MntFruits', 'MntMeatProducts', 'MntFishProducts', 'MntSweetProducts',\n",
    "            'MntGoldProds', 'NumDealsPurchases', 'NumWebPurchases',\n",
    "            'NumCatalogPurchases', 'NumStorePurchases', 'NumWebVisitsMonth',\n",
    "            'Z_Revenue']  # Variables predictoras\n",
    "target = 'Response'  # Variable objetivo\n",
    "\n",
    "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(data[features], data[target], test_size=0.2, random_state=42)\n",
    "\n",
    "# Aplicar oversampling al conjunto de entrenamiento\n",
    "oversampler = RandomOverSampler(random_state=42)\n",
    "X_train_resampled, y_train_resampled = oversampler.fit_resample(X_train, y_train)\n",
    "\n",
    "# Crear el pipeline con escalado de características y modelo de clasificación\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('model', None)\n",
    "])\n",
    "\n",
    "# Definir los parámetros del grid search para cada modelo\n",
    "param_grid = [\n",
    "    {\n",
    "        'model': [LogisticRegression(solver='liblinear')],\n",
    "        'model__C': [0.1, 1, 10]\n",
    "    },\n",
    "    {\n",
    "        'model': [DecisionTreeClassifier()],\n",
    "        'model__max_depth': [8, 10, 15]\n",
    "    },\n",
    "    {\n",
    "        'model': [RandomForestClassifier()],\n",
    "        'model__n_estimators': [50, 100, 200]\n",
    "    },\n",
    "    {\n",
    "        'model': [SVC()],\n",
    "        'model__C': [0.1, 1, 10],\n",
    "        'model__kernel': ['linear', 'rbf']\n",
    "    },\n",
    "    {\n",
    "        'model': [KNeighborsClassifier()],\n",
    "        'model__n_neighbors': [3, 5, 7]\n",
    "    },\n",
    "    {\n",
    "        'model': [KMeans()],\n",
    "        'model__n_clusters': [2, 3, 4]\n",
    "    }\n",
    "]\n",
    "\n",
    "# Realizar la búsqueda de hiperparámetros utilizando GridSearchCV\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Obtener los resultados de la búsqueda de hiperparámetros\n",
    "results = grid_search.cv_results_\n",
    "best_model = grid_search.best_estimator_\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "# Imprimir los resultados\n",
    "print(\"Resultados de la búsqueda de hiperparámetros:\")\n",
    "print(\"Mejor modelo:\", best_model)\n",
    "print(\"Mejores parámetros:\", best_params)\n",
    "print(\"Mejor puntuación:\", best_score)\n",
    "\n",
    "# Evaluar el mejor modelo en el conjunto de prueba\n",
    "y_pred = best_model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "# Imprimir las métricas de evaluación\n",
    "print(\"Métricas de evaluación en el conjunto de prueba:\")\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1-score:\", f1)\n",
    "print(\"ROC AUC:\", roc_auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Guardar el mejor modelo en un archivo pickle\n",
    "with open('models\\mejor_modelo.pkl', 'wb') as file:\n",
    "    pickle.dump(best_model, file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1212\n",
       "1     221\n",
       "Name: Response, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming 'y' is your target variable\n",
    "y_train.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['index', 'ID', 'Year_Birth', 'Education', 'Marital_Status', 'Income',\n",
       "       'Dt_Customer', 'Recency', 'MntWines', 'MntFruits', 'MntMeatProducts',\n",
       "       'MntFishProducts', 'MntSweetProducts', 'MntGoldProds',\n",
       "       'NumDealsPurchases', 'NumWebPurchases', 'NumCatalogPurchases',\n",
       "       'NumStorePurchases', 'NumWebVisitsMonth', 'AcceptedCmp3',\n",
       "       'AcceptedCmp4', 'AcceptedCmp5', 'AcceptedCmp1', 'AcceptedCmp2',\n",
       "       'Complain', 'Z_Revenue', 'Response', 'Marital_Status_Binary', 'Kids',\n",
       "       'date', 'monto_gastado'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1792 entries, 0 to 1791\n",
      "Data columns (total 31 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   index                  1792 non-null   int64  \n",
      " 1   ID                     1792 non-null   int64  \n",
      " 2   Year_Birth             1792 non-null   int64  \n",
      " 3   Education              1792 non-null   object \n",
      " 4   Marital_Status         1792 non-null   object \n",
      " 5   Income                 1792 non-null   float64\n",
      " 6   Dt_Customer            1792 non-null   object \n",
      " 7   Recency                1792 non-null   int64  \n",
      " 8   MntWines               1792 non-null   int64  \n",
      " 9   MntFruits              1792 non-null   int64  \n",
      " 10  MntMeatProducts        1792 non-null   int64  \n",
      " 11  MntFishProducts        1792 non-null   int64  \n",
      " 12  MntSweetProducts       1792 non-null   int64  \n",
      " 13  MntGoldProds           1792 non-null   int64  \n",
      " 14  NumDealsPurchases      1792 non-null   int64  \n",
      " 15  NumWebPurchases        1792 non-null   int64  \n",
      " 16  NumCatalogPurchases    1792 non-null   int64  \n",
      " 17  NumStorePurchases      1792 non-null   int64  \n",
      " 18  NumWebVisitsMonth      1792 non-null   int64  \n",
      " 19  AcceptedCmp3           1792 non-null   int64  \n",
      " 20  AcceptedCmp4           1792 non-null   int64  \n",
      " 21  AcceptedCmp5           1792 non-null   int64  \n",
      " 22  AcceptedCmp1           1792 non-null   int64  \n",
      " 23  AcceptedCmp2           1792 non-null   int64  \n",
      " 24  Complain               1792 non-null   int64  \n",
      " 25  Z_Revenue              1792 non-null   int64  \n",
      " 26  Response               1792 non-null   int64  \n",
      " 27  Marital_Status_Binary  1792 non-null   int64  \n",
      " 28  Kids                   1792 non-null   int64  \n",
      " 29  date                   1792 non-null   object \n",
      " 30  monto_gastado          1792 non-null   int64  \n",
      "dtypes: float64(1), int64(26), object(4)\n",
      "memory usage: 434.1+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "\nAll the 135 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n27 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\de969\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\de969\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py\", line 345, in fit\n    X, y = self._validate_data(\n  File \"C:\\Users\\de969\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\base.py\", line 584, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"C:\\Users\\de969\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\utils\\validation.py\", line 1106, in check_X_y\n    X = check_array(\n  File \"C:\\Users\\de969\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\utils\\validation.py\", line 879, in check_array\n    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)\n  File \"C:\\Users\\de969\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\utils\\_array_api.py\", line 185, in _asarray_with_order\n    array = numpy.asarray(array, order=order, dtype=dtype)\n  File \"C:\\Users\\de969\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\generic.py\", line 2070, in __array__\n    return np.asarray(self._values, dtype=dtype)\nValueError: could not convert string to float: 'Graduation'\n\n--------------------------------------------------------------------------------\n108 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\de969\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\de969\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py\", line 345, in fit\n    X, y = self._validate_data(\n  File \"C:\\Users\\de969\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\base.py\", line 584, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"C:\\Users\\de969\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\utils\\validation.py\", line 1106, in check_X_y\n    X = check_array(\n  File \"C:\\Users\\de969\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\utils\\validation.py\", line 879, in check_array\n    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)\n  File \"C:\\Users\\de969\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\utils\\_array_api.py\", line 185, in _asarray_with_order\n    array = numpy.asarray(array, order=order, dtype=dtype)\n  File \"C:\\Users\\de969\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\generic.py\", line 2070, in __array__\n    return np.asarray(self._values, dtype=dtype)\nValueError: could not convert string to float: '2n Cycle'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 16\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[39m# Realizar la búsqueda en cuadrícula\u001b[39;00m\n\u001b[0;32m     15\u001b[0m grid_search \u001b[39m=\u001b[39m GridSearchCV(model, param_grid, cv\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m)\n\u001b[1;32m---> 16\u001b[0m grid_search\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n\u001b[0;32m     18\u001b[0m \u001b[39m# Obtener el mejor modelo y sus hiperparámetros\u001b[39;00m\n\u001b[0;32m     19\u001b[0m best_model \u001b[39m=\u001b[39m grid_search\u001b[39m.\u001b[39mbest_estimator_\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_search.py:874\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    868\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_results(\n\u001b[0;32m    869\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    870\u001b[0m     )\n\u001b[0;32m    872\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n\u001b[1;32m--> 874\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_search(evaluate_candidates)\n\u001b[0;32m    876\u001b[0m \u001b[39m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[39m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    878\u001b[0m first_test_score \u001b[39m=\u001b[39m all_out[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtest_scores\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_search.py:1388\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1386\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_search\u001b[39m(\u001b[39mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1387\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1388\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparam_grid))\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_search.py:851\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    844\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m!=\u001b[39m n_candidates \u001b[39m*\u001b[39m n_splits:\n\u001b[0;32m    845\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    846\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mcv.split and cv.get_n_splits returned \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    847\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39minconsistent results. Expected \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    848\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39msplits, got \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(n_splits, \u001b[39mlen\u001b[39m(out) \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m n_candidates)\n\u001b[0;32m    849\u001b[0m     )\n\u001b[1;32m--> 851\u001b[0m _warn_or_raise_about_fit_failures(out, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49merror_score)\n\u001b[0;32m    853\u001b[0m \u001b[39m# For callable self.scoring, the return type is only know after\u001b[39;00m\n\u001b[0;32m    854\u001b[0m \u001b[39m# calling. If the return type is a dictionary, the error scores\u001b[39;00m\n\u001b[0;32m    855\u001b[0m \u001b[39m# can now be inserted with the correct key. The type checking\u001b[39;00m\n\u001b[0;32m    856\u001b[0m \u001b[39m# of out will be done in `_insert_error_scores`.\u001b[39;00m\n\u001b[0;32m    857\u001b[0m \u001b[39mif\u001b[39;00m callable(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscoring):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py:367\u001b[0m, in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[1;34m(results, error_score)\u001b[0m\n\u001b[0;32m    360\u001b[0m \u001b[39mif\u001b[39;00m num_failed_fits \u001b[39m==\u001b[39m num_fits:\n\u001b[0;32m    361\u001b[0m     all_fits_failed_message \u001b[39m=\u001b[39m (\n\u001b[0;32m    362\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mAll the \u001b[39m\u001b[39m{\u001b[39;00mnum_fits\u001b[39m}\u001b[39;00m\u001b[39m fits failed.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    363\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mIt is very likely that your model is misconfigured.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    364\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mYou can try to debug the error by setting error_score=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mraise\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    365\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mBelow are more details about the failures:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mfit_errors_summary\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    366\u001b[0m     )\n\u001b[1;32m--> 367\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[0;32m    369\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    370\u001b[0m     some_fits_failed_message \u001b[39m=\u001b[39m (\n\u001b[0;32m    371\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mnum_failed_fits\u001b[39m}\u001b[39;00m\u001b[39m fits failed out of a total of \u001b[39m\u001b[39m{\u001b[39;00mnum_fits\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    372\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThe score on these train-test partitions for these parameters\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    376\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mBelow are more details about the failures:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mfit_errors_summary\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    377\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: \nAll the 135 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n27 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\de969\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\de969\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py\", line 345, in fit\n    X, y = self._validate_data(\n  File \"C:\\Users\\de969\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\base.py\", line 584, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"C:\\Users\\de969\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\utils\\validation.py\", line 1106, in check_X_y\n    X = check_array(\n  File \"C:\\Users\\de969\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\utils\\validation.py\", line 879, in check_array\n    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)\n  File \"C:\\Users\\de969\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\utils\\_array_api.py\", line 185, in _asarray_with_order\n    array = numpy.asarray(array, order=order, dtype=dtype)\n  File \"C:\\Users\\de969\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\generic.py\", line 2070, in __array__\n    return np.asarray(self._values, dtype=dtype)\nValueError: could not convert string to float: 'Graduation'\n\n--------------------------------------------------------------------------------\n108 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\de969\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\de969\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py\", line 345, in fit\n    X, y = self._validate_data(\n  File \"C:\\Users\\de969\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\base.py\", line 584, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"C:\\Users\\de969\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\utils\\validation.py\", line 1106, in check_X_y\n    X = check_array(\n  File \"C:\\Users\\de969\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\utils\\validation.py\", line 879, in check_array\n    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)\n  File \"C:\\Users\\de969\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\utils\\_array_api.py\", line 185, in _asarray_with_order\n    array = numpy.asarray(array, order=order, dtype=dtype)\n  File \"C:\\Users\\de969\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\generic.py\", line 2070, in __array__\n    return np.asarray(self._values, dtype=dtype)\nValueError: could not convert string to float: '2n Cycle'\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Definir los hiperparámetros y sus posibles valores\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 5, 10],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "# Crear el modelo\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "# Realizar la búsqueda en cuadrícula\n",
    "grid_search = GridSearchCV(model, param_grid, cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Obtener el mejor modelo y sus hiperparámetros\n",
    "best_model = grid_search.best_estimator_\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "# Entrenar el mejor modelo con los datos completos\n",
    "best_model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recuento de clases:\n",
      "0    1520\n",
      "1     272\n",
      "Name: Response, dtype: int64\n",
      "\n",
      "Porcentaje de clases:\n",
      "0    84.821429\n",
      "1    15.178571\n",
      "Name: Response, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Supongamos que el DataFrame tiene una columna llamada 'target' que representa la variable objetivo\n",
    "\n",
    "# Calcular el recuento de las clases\n",
    "clases = data['Response'].value_counts()\n",
    "\n",
    "# Calcular el porcentaje de cada clase\n",
    "porcentaje_clases = clases / len(data) * 100\n",
    "\n",
    "# Mostrar los resultados\n",
    "print(\"Recuento de clases:\")\n",
    "print(clases)\n",
    "print(\"\\nPorcentaje de clases:\")\n",
    "print(porcentaje_clases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados de la búsqueda de hiperparámetros para SMOTE + TomekLinks:\n",
      "Mejor modelo: Pipeline(steps=[('scaler', StandardScaler()), ('resampler', SMOTE()),\n",
      "                ('undersampler', TomekLinks(sampling_strategy='majority')),\n",
      "                ('classifier', RandomForestClassifier())])\n",
      "Mejores parámetros: {'classifier__n_estimators': 100}\n",
      "Mejor puntuación: 0.8646036889939328\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import TomekLinks\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "# Crear el pipeline con escalado de características, técnica de resampling y modelo de clasificación\n",
    "pipeline_smote_tomek = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('resampler', SMOTE(sampling_strategy='auto')),\n",
    "    ('undersampler', TomekLinks(sampling_strategy='majority')),\n",
    "    ('classifier', RandomForestClassifier())\n",
    "])\n",
    "\n",
    "# Definir los parámetros del grid search\n",
    "param_grid_smote_tomek = {\n",
    "    'classifier__n_estimators': [50, 100, 200]\n",
    "}\n",
    "\n",
    "# Realizar la búsqueda de hiperparámetros utilizando GridSearchCV\n",
    "grid_search_smote_tomek = GridSearchCV(pipeline_smote_tomek, param_grid_smote_tomek, cv=5, scoring='accuracy')\n",
    "grid_search_smote_tomek.fit(X_train, y_train)\n",
    "\n",
    "# Obtener los resultados de la búsqueda de hiperparámetros\n",
    "best_model_smote_tomek = grid_search_smote_tomek.best_estimator_\n",
    "best_params_smote_tomek = grid_search_smote_tomek.best_params_\n",
    "best_score_smote_tomek = grid_search_smote_tomek.best_score_\n",
    "\n",
    "# Imprimir los resultados\n",
    "print(\"Resultados de la búsqueda de hiperparámetros para SMOTE + TomekLinks:\")\n",
    "print(\"Mejor modelo:\", best_model_smote_tomek)\n",
    "print(\"Mejores parámetros:\", best_params_smote_tomek)\n",
    "print(\"Mejor puntuación:\", best_score_smote_tomek)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
